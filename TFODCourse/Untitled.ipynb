{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aafd5d92-7689-453c-8017-7347c7729ee3",
   "metadata": {},
   "source": [
    "## Collection des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac32bb57-55d3-4d06-bd19-c82eaa20b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100b5580-cee1-4b81-bdf4-88680351a34e",
   "metadata": {},
   "source": [
    "## Importation des Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6a3a5dc-d344-48f7-9101-c78f30934875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV\n",
    "import cv2\n",
    "\n",
    "# uuid\n",
    "import uuid\n",
    "\n",
    "## Opérations sur le Système d'exploitation\n",
    "import os\n",
    "\n",
    "# la gestion du temps\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecf3409-4462-46eb-a1c8-fe4745631e00",
   "metadata": {},
   "source": [
    "## Définition des images à collecter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6440691d-881d-494d-8f73-59b7ab1ab8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = ['thumbsup', 'thumbsdown', 'thankyou', 'livelong']\n",
    "labels = ['lunette', 'brosseadent', 'patedentifrice', 'montre', 'peignecheveux',  'telephone', 'livre',]\n",
    "number_images = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0450c1-30bc-4a40-ac4d-2dfc1d5cf55d",
   "metadata": {},
   "source": [
    "## Configuration du dossier des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2be974-0c7c-4f47-b6a7-9328e4089ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = os.path.join('.', 'tensorflow', 'workspace', 'images', 'collectedimages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09cc932-1796-4f0a-ae29-21181c3746cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1867edb3-5f6c-4dfe-a451-12571abea851",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(IMAGES_PATH):\n",
    "    if os.name == 'posix':\n",
    "        !mkdir - {IMAGES_PATH}\n",
    "    if os.name == 'nt':\n",
    "        !mkdir {IMAGES_PATH}\n",
    "        \n",
    "for label in labels:\n",
    "    path = os.path.join(IMAGES_PATH, label)\n",
    "    if not os.path.exists(path):\n",
    "        !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dac9633-172b-43b0-95c3-7ffe6034c9a2",
   "metadata": {},
   "source": [
    "## Capture des Images WebCam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90488f39-b900-4a3b-81a6-1a46280a0372",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    cap = cv2.VideoCapture(0) # Se connecter à son webcam\n",
    "    print(f'Récuperer l\\'image pour {label}')\n",
    "    time.sleep(5)\n",
    "    for imgnum in range(number_images):\n",
    "        print('Collecting image {}'.format(imgnum))\n",
    "        ret, frame = cap.read()\n",
    "        imgname = os.path.join(IMAGES_PATH,label,label+'.'+'{}.jpg'.format(str(uuid.uuid1())))\n",
    "        cv2.imwrite(imgname, frame)\n",
    "        cv2.imshow('frame', frame)\n",
    "        time.sleep(2)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4075cc6-0d4c-4715-9498-645fc8a0f4e9",
   "metadata": {},
   "source": [
    "## Etiquetage des Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81557e5-2932-4990-be47-aafac8c59c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pyqt5 lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d1b23e-d0af-44a8-8e52-a00352add30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b15a5c-2364-4f16-80bf-ec0e2a6f4501",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_IMAGES_PATH = os.path.join('.', 'tensorflow', 'labelimg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ad5286-77ee-44f8-8602-81106152bc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(LABEL_IMAGES_PATH):\n",
    "    !mkdir {LABEL_IMAGES_PATH}\n",
    "    !git clone https://github.com/tzutalin/labelImg {LABEL_IMAGES_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3954bd55-d7ef-4721-aca4-1e49204c785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'posix':\n",
    "    !make qt5py3\n",
    "if os.name =='nt':\n",
    "    !cd {LABEL_IMAGES_PATH} && pyrcc5 -o libs/resources.py resources.qrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651d38cb-9f9f-43b5-83e3-d9dc7455f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd {LABEL_IMAGES_PATH} && python labelImg.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1110dcda-94c3-4670-b924-bc4ff30a280c",
   "metadata": {},
   "source": [
    "## Déplacez-les dans une partition de train et de test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff033ba-de19-4b12-b704-f559c190e9bb",
   "metadata": {},
   "source": [
    "## FACULTATIF -  Compressez-les pour l'entrinement Colab¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d910359-04e0-4292-800f-9e9e11b1fa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'train')\n",
    "TEST_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'test')\n",
    "ARCHIVE_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'archive.tar.gz')\n",
    "ARCHIVE_PATH_Win = os.path.join('Tensorflow', 'workspace', 'images', 'archive.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa996fb-0150-4159-a517-662b1956e3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czf {ARCHIVE_PATH} {TRAIN_PATH} {TEST_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fc6cbd-ca96-4030-9a98-b7b7861e47a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar -czf {ARCHIVE_PATH_Win} {TRAIN_PATH} {TEST_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bf0434-9646-4d49-b2af-a426a1de8277",
   "metadata": {},
   "source": [
    "## Entraînez le modèle tfod à l'aide des scripts fournis, cela peut prendre un peu de temps en fonction de votre machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12d2b849-b0fd-436d-8f78-779753a9cd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dbaf0ae-7631-4854-9904-00d50e110da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfd9aeab-dd34-44e0-b5cc-f11369c86408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = {\n",
    "#     'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "#     'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "#     'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fd58dea-386f-4711-930b-3312a00e1986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in paths.values():\n",
    "#     if not os.path.exists(path):\n",
    "#         if os.name == 'posix':\n",
    "#             !mkdir -p {path}\n",
    "#         if os.name == 'nt':\n",
    "#             !mkdir {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509c340b-5fc3-45e4-bb9a-cd69e7430102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ddc576e-b2ee-438a-bed0-17a896072d48",
   "metadata": {},
   "source": [
    "##  Téléchargez des modèles pré-entraînés de modèles TF à partir de Tensorflow Model Zoo et installez TFOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa44e27f-0a56-429f-89db-0eec4fa3fb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\damaro\\detection_objet_tensorflow\\tfodcourse\\tfod\\lib\\site-packages (3.2)\n"
     ]
    }
   ],
   "source": [
    "if os.name=='nt':\n",
    "    !pip install wget\n",
    "    import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965e3d00-d7b8-4e65-b727-dec5201631fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "#     !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cf8280-62af-4c09-9a81-bc2abf12b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.name=='posix':  \n",
    "#     !apt-get install protobuf-compiler\n",
    "#     !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
    "    \n",
    "# if os.name=='nt':\n",
    "#     url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "#     wget.download(url)\n",
    "#     !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "#     !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "#     os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
    "#     !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "#     !cd Tensorflow/models/research/slim && pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3a3183-2e84-4692-8db7-841158e87582",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c96691-4dd2-47fc-936b-b7d6b3dcbffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall protobuf matplotlib -y\n",
    "!pip install protobuf matplotlib==3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92c08b0f-9b63-4c13-8a0d-d1703c265e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2186a840-0ef5-45a5-8582-83381a0d60e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version             Editable project location\n",
      "---------------------------- ------------------- -------------------------------------------------------------------------------------\n",
      "absl-py                      1.0.0\n",
      "apache-beam                  2.37.0rc2\n",
      "asttokens                    2.0.5\n",
      "astunparse                   1.6.3\n",
      "avro-python3                 1.10.2\n",
      "backcall                     0.2.0\n",
      "black                        22.1.0\n",
      "cachetools                   5.0.0\n",
      "certifi                      2021.10.8\n",
      "charset-normalizer           2.0.12\n",
      "click                        8.0.4\n",
      "colorama                     0.4.4\n",
      "contextlib2                  21.6.0\n",
      "cycler                       0.11.0\n",
      "Cython                       3.0.0a10\n",
      "debugpy                      1.5.1\n",
      "decorator                    5.1.1\n",
      "entrypoints                  0.4\n",
      "executing                    0.8.2\n",
      "flatbuffers                  2.0\n",
      "gast                         0.5.3\n",
      "google-auth                  2.6.0\n",
      "google-auth-oauthlib         0.4.6\n",
      "google-pasta                 0.2.0\n",
      "grpcio                       1.44.0\n",
      "h5py                         3.6.0\n",
      "idna                         3.3\n",
      "importlib-metadata           4.11.1\n",
      "ipykernel                    6.9.1\n",
      "ipython                      8.0.1\n",
      "jedi                         0.18.1\n",
      "jupyter-client               7.1.2\n",
      "jupyter-core                 4.9.2\n",
      "keras                        2.8.0\n",
      "Keras-Preprocessing          1.1.2\n",
      "kiwisolver                   1.3.2\n",
      "libclang                     13.0.0\n",
      "lvis                         0.5.3\n",
      "lxml                         4.8.0\n",
      "Markdown                     3.3.6\n",
      "matplotlib                   3.2.0\n",
      "matplotlib-inline            0.1.3\n",
      "mypy-extensions              0.4.3\n",
      "nest-asyncio                 1.5.4\n",
      "numpy                        1.22.2\n",
      "oauthlib                     3.2.0\n",
      "object-detection             0.1\n",
      "opencv-python                4.5.5.62\n",
      "opt-einsum                   3.3.0\n",
      "pandas                       1.4.1\n",
      "parso                        0.8.3\n",
      "pathspec                     0.9.0\n",
      "pi                           0.1.2\n",
      "pickleshare                  0.7.5\n",
      "Pillow                       9.0.1\n",
      "pip                          22.0.3\n",
      "platformdirs                 2.5.1\n",
      "prompt-toolkit               3.0.28\n",
      "protobuf                     3.19.4\n",
      "pure-eval                    0.2.2\n",
      "pyasn1                       0.4.8\n",
      "pyasn1-modules               0.2.8\n",
      "pycocotools                  2.0.4\n",
      "Pygments                     2.11.2\n",
      "pyparsing                    3.0.7\n",
      "PyQt5                        5.15.6\n",
      "PyQt5-Qt5                    5.15.2\n",
      "PyQt5-sip                    12.9.1\n",
      "python-dateutil              2.8.2\n",
      "pywin32                      303\n",
      "pyzmq                        22.3.0\n",
      "requests                     2.27.1\n",
      "requests-oauthlib            1.3.1\n",
      "rsa                          4.8\n",
      "scipy                        1.8.0\n",
      "setuptools                   47.1.0\n",
      "six                          1.16.0\n",
      "slim                         0.1                 c:\\users\\damaro\\detection_objet_tensorflow\\tfodcourse\\tensorflow\\models\\research\\slim\n",
      "stack-data                   0.2.0\n",
      "tensorboard                  2.8.0\n",
      "tensorboard-data-server      0.6.1\n",
      "tensorboard-plugin-wit       1.8.1\n",
      "tensorflow                   2.8.0\n",
      "tensorflow-io                0.24.0\n",
      "tensorflow-io-gcs-filesystem 0.24.0\n",
      "termcolor                    1.1.0\n",
      "tf-estimator-nightly         2.8.0.dev2021122109\n",
      "tf-models-official           2.8.0\n",
      "tf-slim                      1.1.0\n",
      "tomli                        2.0.1\n",
      "tornado                      6.1\n",
      "traitlets                    5.1.1\n",
      "typing_extensions            4.1.1\n",
      "urllib3                      1.26.8\n",
      "wcwidth                      0.2.5\n",
      "Werkzeug                     2.0.3\n",
      "wget                         3.2\n",
      "wheel                        0.37.1\n",
      "wrapt                        1.13.3\n",
      "zipp                         3.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8bb4706-cd2a-4907-a8bb-cdaff4f850a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [.................................................................] 20515344 / 20515344        1 fichier(s) d‚plac‚(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "if os.name =='posix':\n",
    "    !wget {PRETRAINED_MODEL_URL}\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "if os.name == 'nt':\n",
    "    wget.download(PRETRAINED_MODEL_URL)\n",
    "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3402120-dbaf-4eec-930b-bc01a28f1163",
   "metadata": {},
   "source": [
    "## Create Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b23178f-1d81-4ec1-a77e-b27b9ae2aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = [{'name':'ThumbsUp', 'id':1}, {'name':'ThumbsDown', 'id':2}, {'name':'ThankYou', 'id':3}, {'name':'LiveLong', 'id':4}]\n",
    "labels = [\n",
    "    {'name': 'lunette', 'id': 1}, \n",
    "    {'name': 'brosseadent', 'id': 2},\n",
    "    {'name': 'patedentifrice', 'id': 3},\n",
    "    {'name': 'montre', 'id': 4},\n",
    "    {'name': 'peignecheveux', 'id': 5},\n",
    "    {'name': 'telephone', 'id': 6},\n",
    "    {'name': 'livre', 'id': 7}\n",
    "]\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e808398-e112-4795-8383-4f99d024b735",
   "metadata": {},
   "source": [
    "## Create TF records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a62d8a43-96b6-4184-aa92-9f8be10f787e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x Tensorflow/workspace/images/train/\n",
      "x Tensorflow/workspace/images/train/brosseadent.25ef7cbb-95ff-11ec-b965-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/brosseadent.25ef7cbb-95ff-11ec-b965-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/brosseadent.285d9682-95ff-11ec-9bda-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/brosseadent.285d9682-95ff-11ec-9bda-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/brosseadent.2992bb2a-95ff-11ec-a335-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/brosseadent.2992bb2a-95ff-11ec-a335-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/brosseadent.2ac7dfcb-95ff-11ec-9db0-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/brosseadent.2ac7dfcb-95ff-11ec-9db0-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/brosseadent.2bffc381-95ff-11ec-b481-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/brosseadent.2bffc381-95ff-11ec-b481-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/brosseadent.2d35d284-95ff-11ec-bbcf-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/brosseadent.2d35d284-95ff-11ec-bbcf-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/livre.64a3e2d1-95ff-11ec-a639-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/livre.64a3e2d1-95ff-11ec-a639-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/livre.65d89234-95ff-11ec-9b5e-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/livre.65d89234-95ff-11ec-9b5e-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/livre.670e7a2e-95ff-11ec-9e99-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/livre.670e7a2e-95ff-11ec-9e99-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/livre.697f2c09-95ff-11ec-a28b-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/livre.697f2c09-95ff-11ec-a28b-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/livre.6ab4c5d4-95ff-11ec-a45d-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/livre.6ab4c5d4-95ff-11ec-a45d-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/livre.6bed9424-95ff-11ec-aa8e-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/livre.6bed9424-95ff-11ec-aa8e-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/lunette.1943ed43-95ff-11ec-9957-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/lunette.1943ed43-95ff-11ec-9957-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/lunette.1a7c4636-95ff-11ec-affc-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/lunette.1a7c4636-95ff-11ec-affc-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/lunette.1bb450e5-95ff-11ec-8bab-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/lunette.1bb450e5-95ff-11ec-8bab-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/lunette.1ced944b-95ff-11ec-bbaf-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/lunette.1ced944b-95ff-11ec-bbaf-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/lunette.1e24b4af-95ff-11ec-a552-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/lunette.1e24b4af-95ff-11ec-a552-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/lunette.1f5a4e7a-95ff-11ec-a979-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/lunette.1f5a4e7a-95ff-11ec-a979-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/montre.3f01f1a8-95ff-11ec-b402-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/montre.3f01f1a8-95ff-11ec-b402-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/montre.403541bd-95ff-11ec-be25-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/montre.403541bd-95ff-11ec-be25-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/montre.416d7382-95ff-11ec-bcd9-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/montre.416d7382-95ff-11ec-bcd9-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/montre.42a50912-95ff-11ec-a7fa-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/montre.42a50912-95ff-11ec-a7fa-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/montre.43db1818-95ff-11ec-bd94-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/montre.43db1818-95ff-11ec-bd94-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/montre.451286a2-95ff-11ec-a419-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/montre.451286a2-95ff-11ec-a419-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/patedentifrice.33af3b62-95ff-11ec-bfc7-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/patedentifrice.33af3b62-95ff-11ec-bfc7-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/patedentifrice.34e74637-95ff-11ec-a73b-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/patedentifrice.34e74637-95ff-11ec-a73b-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/patedentifrice.361dca68-95ff-11ec-bced-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/patedentifrice.361dca68-95ff-11ec-bced-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/patedentifrice.37544ea3-95ff-11ec-8dcf-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/patedentifrice.37544ea3-95ff-11ec-8dcf-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/patedentifrice.388a84ab-95ff-11ec-9a1b-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/patedentifrice.388a84ab-95ff-11ec-9a1b-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/patedentifrice.39c06d46-95ff-11ec-93e1-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/patedentifrice.39c06d46-95ff-11ec-93e1-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/peignecheveux.4b908360-95ff-11ec-88df-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/peignecheveux.4b908360-95ff-11ec-88df-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/peignecheveux.4cc64441-95ff-11ec-9278-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/peignecheveux.4cc64441-95ff-11ec-9278-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/peignecheveux.4dff3972-95ff-11ec-b07d-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/peignecheveux.4dff3972-95ff-11ec-b07d-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/peignecheveux.4f35bdab-95ff-11ec-a6a5-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/peignecheveux.4f35bdab-95ff-11ec-a6a5-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/peignecheveux.51a49abe-95ff-11ec-ad51-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/peignecheveux.51a49abe-95ff-11ec-ad51-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/peignecheveux.52db942b-95ff-11ec-8d28-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/peignecheveux.52db942b-95ff-11ec-8d28-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/telephone.581cf246-95ff-11ec-a77e-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/telephone.581cf246-95ff-11ec-a77e-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/telephone.5a89d392-95ff-11ec-ad2f-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/telephone.5a89d392-95ff-11ec-ad2f-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/telephone.5bbcae32-95ff-11ec-b63c-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/telephone.5bbcae32-95ff-11ec-b63c-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/telephone.5cf29618-95ff-11ec-b74a-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/telephone.5cf29618-95ff-11ec-b74a-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/telephone.5e285704-95ff-11ec-8ccf-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/telephone.5e285704-95ff-11ec-8ccf-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/train/telephone.5f5eb422-95ff-11ec-aec2-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/train/telephone.5f5eb422-95ff-11ec-aec2-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/test/\n",
      "x Tensorflow/workspace/images/test/brosseadent.27264fba-95ff-11ec-92be-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/test/brosseadent.27264fba-95ff-11ec-92be-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/test/livre.6848ceed-95ff-11ec-a68e-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/test/livre.6848ceed-95ff-11ec-a68e-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/test/lunette.20905d90-95ff-11ec-bf06-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/test/lunette.20905d90-95ff-11ec-bf06-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/test/montre.4645135c-95ff-11ec-80ac-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/test/montre.4645135c-95ff-11ec-80ac-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/test/patedentifrice.3278902f-95ff-11ec-832a-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/test/patedentifrice.3278902f-95ff-11ec-832a-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/test/peignecheveux.506cde2d-95ff-11ec-9cb1-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/test/peignecheveux.506cde2d-95ff-11ec-9cb1-94e979d6190c.xml\n",
      "x Tensorflow/workspace/images/test/telephone.5950b74a-95ff-11ec-bb5b-94e979d6190c.jpg\n",
      "x Tensorflow/workspace/images/test/telephone.5950b74a-95ff-11ec-bb5b-94e979d6190c.xml\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL IF RUNNING ON COLAB\n",
    "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
    "if os.path.exists(ARCHIVE_FILES):\n",
    "  !tar -zxvf {ARCHIVE_FILES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3bab474-ebd5-4d42-8b6a-ada7cffe1978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Tensorflow\\scripts'...\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
    "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a809002-12bf-4e80-bd77-85a725e400a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"Tensorflow\\scripts\\generate_tfrecord.py\", line 21, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\damaro\\detection_objet_tensorflow\\TFODCourse\\tfod\\lib\\site-packages\\pandas-1.4.1-py3.8-win-amd64.egg\\pandas\\__init__.py\", line 16, in <module>\n",
      "    raise ImportError(\n",
      "ImportError: Unable to import required dependencies:\n",
      "pytz: No module named 'pytz'\n",
      "Traceback (most recent call last):\n",
      "  File \"Tensorflow\\scripts\\generate_tfrecord.py\", line 21, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\damaro\\detection_objet_tensorflow\\TFODCourse\\tfod\\lib\\site-packages\\pandas-1.4.1-py3.8-win-amd64.egg\\pandas\\__init__.py\", line 16, in <module>\n",
      "    raise ImportError(\n",
      "ImportError: Unable to import required dependencies:\n",
      "pytz: No module named 'pytz'\n"
     ]
    }
   ],
   "source": [
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7c5895-9f7a-4513-a8ce-abe080227b52",
   "metadata": {},
   "source": [
    "## Copier la configuration du modèle dans le dossier de formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93c3660b-7894-4fde-a643-2990d018da92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1 fichier(s) copi‚(s).\n"
     ]
    }
   ],
   "source": [
    "if os.name =='posix':\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328a9fed-ab69-423a-b96d-015df72c2602",
   "metadata": {},
   "source": [
    "## Mettre à jour la configuration pour l'apprentissage par transfert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b4672f4-9583-4a9b-8f88-aa30235b2784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a46b0161-c166-4bf6-9735-0c16cde3abc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3311c003-d2bc-4b4d-91ba-4a1812a31963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': ssd {\n",
       "   num_classes: 90\n",
       "   image_resizer {\n",
       "     fixed_shape_resizer {\n",
       "       height: 320\n",
       "       width: 320\n",
       "     }\n",
       "   }\n",
       "   feature_extractor {\n",
       "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
       "     depth_multiplier: 1.0\n",
       "     min_depth: 16\n",
       "     conv_hyperparams {\n",
       "       regularizer {\n",
       "         l2_regularizer {\n",
       "           weight: 3.9999998989515007e-05\n",
       "         }\n",
       "       }\n",
       "       initializer {\n",
       "         random_normal_initializer {\n",
       "           mean: 0.0\n",
       "           stddev: 0.009999999776482582\n",
       "         }\n",
       "       }\n",
       "       activation: RELU_6\n",
       "       batch_norm {\n",
       "         decay: 0.996999979019165\n",
       "         scale: true\n",
       "         epsilon: 0.0010000000474974513\n",
       "       }\n",
       "     }\n",
       "     use_depthwise: true\n",
       "     override_base_feature_extractor_hyperparams: true\n",
       "     fpn {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       additional_layer_depth: 128\n",
       "     }\n",
       "   }\n",
       "   box_coder {\n",
       "     faster_rcnn_box_coder {\n",
       "       y_scale: 10.0\n",
       "       x_scale: 10.0\n",
       "       height_scale: 5.0\n",
       "       width_scale: 5.0\n",
       "     }\n",
       "   }\n",
       "   matcher {\n",
       "     argmax_matcher {\n",
       "       matched_threshold: 0.5\n",
       "       unmatched_threshold: 0.5\n",
       "       ignore_thresholds: false\n",
       "       negatives_lower_than_unmatched: true\n",
       "       force_match_for_each_row: true\n",
       "       use_matmul_gather: true\n",
       "     }\n",
       "   }\n",
       "   similarity_calculator {\n",
       "     iou_similarity {\n",
       "     }\n",
       "   }\n",
       "   box_predictor {\n",
       "     weight_shared_convolutional_box_predictor {\n",
       "       conv_hyperparams {\n",
       "         regularizer {\n",
       "           l2_regularizer {\n",
       "             weight: 3.9999998989515007e-05\n",
       "           }\n",
       "         }\n",
       "         initializer {\n",
       "           random_normal_initializer {\n",
       "             mean: 0.0\n",
       "             stddev: 0.009999999776482582\n",
       "           }\n",
       "         }\n",
       "         activation: RELU_6\n",
       "         batch_norm {\n",
       "           decay: 0.996999979019165\n",
       "           scale: true\n",
       "           epsilon: 0.0010000000474974513\n",
       "         }\n",
       "       }\n",
       "       depth: 128\n",
       "       num_layers_before_predictor: 4\n",
       "       kernel_size: 3\n",
       "       class_prediction_bias_init: -4.599999904632568\n",
       "       share_prediction_tower: true\n",
       "       use_depthwise: true\n",
       "     }\n",
       "   }\n",
       "   anchor_generator {\n",
       "     multiscale_anchor_generator {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       anchor_scale: 4.0\n",
       "       aspect_ratios: 1.0\n",
       "       aspect_ratios: 2.0\n",
       "       aspect_ratios: 0.5\n",
       "       scales_per_octave: 2\n",
       "     }\n",
       "   }\n",
       "   post_processing {\n",
       "     batch_non_max_suppression {\n",
       "       score_threshold: 9.99999993922529e-09\n",
       "       iou_threshold: 0.6000000238418579\n",
       "       max_detections_per_class: 100\n",
       "       max_total_detections: 100\n",
       "       use_static_shapes: false\n",
       "     }\n",
       "     score_converter: SIGMOID\n",
       "   }\n",
       "   normalize_loss_by_num_matches: true\n",
       "   loss {\n",
       "     localization_loss {\n",
       "       weighted_smooth_l1 {\n",
       "       }\n",
       "     }\n",
       "     classification_loss {\n",
       "       weighted_sigmoid_focal {\n",
       "         gamma: 2.0\n",
       "         alpha: 0.25\n",
       "       }\n",
       "     }\n",
       "     classification_weight: 1.0\n",
       "     localization_weight: 1.0\n",
       "   }\n",
       "   encode_background_as_zeros: true\n",
       "   normalize_loc_loss_by_codesize: true\n",
       "   inplace_batchnorm_update: true\n",
       "   freeze_batchnorm: false\n",
       " },\n",
       " 'train_config': batch_size: 128\n",
       " data_augmentation_options {\n",
       "   random_horizontal_flip {\n",
       "   }\n",
       " }\n",
       " data_augmentation_options {\n",
       "   random_crop_image {\n",
       "     min_object_covered: 0.0\n",
       "     min_aspect_ratio: 0.75\n",
       "     max_aspect_ratio: 3.0\n",
       "     min_area: 0.75\n",
       "     max_area: 1.0\n",
       "     overlap_thresh: 0.0\n",
       "   }\n",
       " }\n",
       " sync_replicas: true\n",
       " optimizer {\n",
       "   momentum_optimizer {\n",
       "     learning_rate {\n",
       "       cosine_decay_learning_rate {\n",
       "         learning_rate_base: 0.07999999821186066\n",
       "         total_steps: 50000\n",
       "         warmup_learning_rate: 0.026666000485420227\n",
       "         warmup_steps: 1000\n",
       "       }\n",
       "     }\n",
       "     momentum_optimizer_value: 0.8999999761581421\n",
       "   }\n",
       "   use_moving_average: false\n",
       " }\n",
       " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
       " num_steps: 50000\n",
       " startup_delay_steps: 0.0\n",
       " replicas_to_aggregate: 8\n",
       " max_number_of_boxes: 100\n",
       " unpad_groundtruth_tensors: false\n",
       " fine_tune_checkpoint_type: \"classification\"\n",
       " fine_tune_checkpoint_version: V2,\n",
       " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " },\n",
       " 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
       " use_moving_averages: false,\n",
       " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " }\n",
       " ],\n",
       " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " }}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1c0acb6-957d-4182-833e-d3b8295c9c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4f77d77-44ba-4c37-9c12-5939a2926e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "684474ae-5ff5-4a0e-b776-b43b901672ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4f9209-49b5-49fe-9a80-40adaf6606bc",
   "metadata": {},
   "source": [
    "## Entrainer le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9287ad9f-b8f4-48b8-829d-4bc1e9efc34c",
   "metadata": {},
   "source": [
    "## Conversion en TFJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ee044d-696b-4c2c-93f2-96a1c2fa5e70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfod",
   "language": "python",
   "name": "tfod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
